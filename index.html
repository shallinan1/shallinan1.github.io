<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Skyler Hallinan</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
        <meta charset="utf-8" />
        <meta property="og:title" content="Skyler Hallinan" />
        <meta property="og:image" content="https:/skylerhallinan.com/assets/pictures/profile_pic.jpg" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="author" content="Skyler Hallinan" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <link rel="shortcut icon" type="image/png" href="favicon.ico" />

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous" />
        <link rel="stylesheet" href="css/style.css" />
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    </head>
    <body>
        <style>
            pre {
                text-align: left;
                white-space: pre-line;
            }
        </style>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col">
                    <h1>Skyler Hallinan</h1>
                </div>
            </div>
            <div class="row">
                <div class="col-md-4 order-md-2">
                    <img src="assets/pictures/profile_pic.jpg" alt="Skyler" class="img-fluid rounded float-right" style="max-width: 250px;"/>
                </div>
                <div class="col-md-8 order-md-1">
                    <p>
                        I am a Ph.D. student working on Natural Language Processing and Artificial Intelligence at the <a href="https://www.cs.usc.edu/">University of Southern California</a> advised by Professor <a href="https://www.seanre.com/" target="_blank">Xiang Ren</a>. Previously, I did a B.S./M.S. in computer science at the University of Washington, where I was fortunate to work with <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>. I have also previously worked with <a href="https://homes.cs.washington.edu/~hannaneh/">Hanna Hajishirzi</a>
                    </p>
                    <!-- <p>
                        My broad research goal is to <b>understand the boundaries</b> of machine intelligence and <b>bridge the capability gap</b> between models and humans by exploring alternative paths beyond scaling, such as algorithmic innovations and knowledge enhancement.
                        Over the past few years, I have focused on <b>studying the capabilities and limits</b> of language models, as well as <b>developing learning and inference algorithms</b> to unlock capabilities in smaller models, for example:
                    </p>
                    <ul>
                        <li>I investigate the fundamental limits of Transformer language models in the context of compositional tasks in my work <a href="https://arxiv.org/abs/2305.18654">Faith and Fate</a>. I explore the divergence in the configuration of machine and human intelligence by proposing and testing the <a href="https://arxiv.org/abs/2311.00059">Generative AI Paradox</a>.</li>
                        <li>I have worked to develop a suite of learning and decoding-time methods to empower compact and efficient language models, including <a href="https://arxiv.org/abs/2010.12884">NeuroLogic Decoding</a>, <a href="https://arxiv.org/abs/2112.08726">NeuroLogic A<sup>*</sup>esque Decoding</a>, <a href="https://arxiv.org/abs/2205.13636">Quark</a>, and <a href="https://arxiv.org/abs/2305.15065">Inference-Time Policy Adapters</a>.</li>
                    </ul>  -->
                    <p>
                    I am happy to mentor a few self-motivated undergraduate and master students. Please feel free to reach out if you are interested in working with me!
                    </p>
                    <p>Email: shallina [<a href="https://en.wikipedia.org/wiki/At_sign" target="_blank">at</a>] usc.edu</p>
                    <!-- <p>Links: [<a href="https://scholar.google.com/citations?user=ssYPSmkAAAAJ&hl=en" target="_blank">Google Scholar</a>] [<a href="https://twitter.com/gximing?lang=en" target="_blank">Twitter</a>] [<a href="https://github.com/GXimingLu" target="_blank">Github</a>] [<a href="img/Ximing_Lu_CV.pdf" target="_blank">CV</a>] [<a href="img/Research_Statement.pdf" target="_blank">Research Statement</a>]</p> -->
                </div>
            </div>
            <hr />
            <div class="row" id="publications">
                <div class="col">
                    <p>Publications are listed in reverse chronological order. <br> For the most up-to-date and comprehensive list of my publications, please see my <a href="https://scholar.google.com/citations?user=ztXdO4gAAAAJ&hl=en">Google Scholar</a>.</p>
                    <h2>Preprints</h2>
                    <ul>
                        <li>
                            <a href="https://arxiv.org/abs/2410.04265">AI as Humanity's Salieri: Quantifying Linguistic Creativity of Language Models via Systematic Attribution of Machine Text against Web Text</a><br>
                            Ximing Lu, Melanie Sclar, <b>Skyler Hallinan</b>, Niloofar Mireshghallah, Jiacheng Liu, Seungju Han, Allyson Ettinger, Liwei Jiang, Khyathi Chandu, Nouha Dziri, Yejin Choi
                            <br><br>
                        </li>
                    </ul>
                    <h2>Publications</h2>
                    <ul>
                        <li>
                            <a href="https://arxiv.org/abs/2408.15666v1">StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements</a>
                            Jillian Fisher*, <b>Skyler Hallinan</b>*, Ximing Lu, Mitchell Gordon, Zaid Harchaoui, Yejin Choi<br>
                            EMNLP 2024 <br><br>
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2311.02805">Tailoring Self-Rationalizers with Multi-Reward Distillation</a><br>
                            Sahana Ramnath, Brihi Joshi, <strong>Skyler Hallinan</strong>, Ximing Lu, Liunian Harold Li, Aaron Chan, Jack Hessel, Yejin Choi, Xiang Ren<br>
                            ICLR 2024 <br><br>
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2305.15065"><b>Inference-time Policy Adapters (IPA):</b> Tailoring Extreme-Scale LMs Without Fine-Tuning</a><br>
                            Ximing Lu, Faeze Brahman, Peter West, Jaehun Jung, Khyathi Chandu, Abhilasha Ravichander, Prithviraj Ammanabrolu, Liwei Jiang, Sahana Ramnath, Nouha Dziri, Jillian Fisher, Bill Lin, <strong>Skyler Hallinan</strong>, Lianhui Qin, Xiang Ren, Sean Welleck, Yejin Choi <br>
                            EMNLP 2023 <br><br>
                        </li>

                        <li>
                            <a href="https://arxiv.org/abs/2311.07167"><b>STEER</b>: Unified Style Transfer with Expert Reinforcement</a><br>
                            <strong>Skyler Hallinan</strong>, Faeze Brahman, Ximing Lu, Jaehun Jung, Sean Welleck, Yejin Choi <br>
                            Findings of EMNLP 2023 <br><br>
                        </li>

                        <li>
                            <a href="https://arxiv.org/abs/2210.03078"><b>Rainier:</b> Reinforced Knowledge Introspector for Commonsense Question Answering</a><br>
                            Jiacheng Liu, <strong>Skyler Hallinan</strong>, Ximing Lu, Pengfei He, Sean Welleck, Hannaneh Hajishirzi, Yejin Choi<br>
                            EMNLP 2022 <br><br>
                        </li>
                    </ul>
                </div>
            </div>

            <hr />
            <div class="row">
                <div class="col">
                    <h2>Honors & Awards</h2>
                    <ul>
                        <li>
                            (2021) <a href="https://news.cs.washington.edu/2021/06/18/every-single-one-of-you-has-what-it-takes-to-do-great-things-a-tribute-to-the-allen-school-class-of-2021/">Outstanding Senior Award</a>, Paul G. Allen School of Computer Science & Engineering<br>
                        </li>
                        <li>
                            (2020) <a href="https://news.cs.washington.edu/2020/11/03/allen-school-recognizes-undergraduates-ximing-lu-and-sanjana-chintalapati-during-annual-celebration-of-diversity-in-computing/">Lisa Simonyi Prize</a>, Paul G. Allen School of Computer Science & Engineering<br>
                        </li>
                        <li>
                            (2020) <a href="https://news.cs.washington.edu/2020/12/14/six-allen-school-undergraduates-recognized-for-excellence-in-research/">Levinson Emerging Scholars Award</a>, Univisersity of Washington<br>
                        </li>
                        <li>
                            (2020) Mary Gates Research Scholarship, Univisersity of Washington<br>
                        </li>
                        <li>
                            (2019) Denton, Denice Dee Scholars Endowment, Paul G. Allen School of Computer Science & Engineering<br>
                        </li>
                        <li>
                            (2019) Conference Travel Award, Univisersity of Washington<br>
                        </li>
                    </ul>
                </div>
            </div>
            <hr />
            <div class="row">
                <div class="col">
                    <h2>Teaching Experience</h2>
                    <ul>
                        <!-- Teaching experiences can be listed here -->
                        <li>
                            (Winter, 2024) TA @ CSE 447/517 (Undergrad/Grad NLP) at University of Washington
                        </li>
                    </ul>
                </div>
            </div>
            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                        <p class="h5 text-muted">
                            Skyler Hallinan, 2024
                        </p>
                    </div>
                </div>
            </footer>
        </div>
    </body>
</html>
